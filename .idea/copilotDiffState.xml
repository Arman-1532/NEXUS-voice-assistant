<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/.gitignore">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/.gitignore" />
              <option name="updatedContent" value=".env&#10;# Virtual environments&#10;venv/&#10;.env.local&#10;# Python cache&#10;__pycache__/&#10;*.py[cod]&#10;# macOS&#10;.DS_Store&#10;# IDEs&#10;.idea/&#10;.vscode/&#10;# Logs&#10;*.log&#10;# Persistent system files&#10;Thumbs.db&#10;# Optional: Python egg/build&#10;dist/&#10;build/&#10;*.egg-info/&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/client.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/client.py" />
              <option name="updatedContent" value="# Minimal OpenAI client for NAFIS-voice-assistant&#10;# - Reads OPENAI_API_KEY from the environment (supports .env via python-dotenv)&#10;# - Exposes get_response(prompt) for other modules to call&#10;# - When run as a script, accepts a prompt via CLI args or interactive input&#10;&#10;from dotenv import load_dotenv&#10;import os&#10;import sys&#10;import openai&#10;&#10;load_dotenv()&#10;&#10;API_KEY = os.getenv(&quot;OPENAI_API_KEY&quot;)&#10;if API_KEY:&#10;    openai.api_key = API_KEY&#10;&#10;&#10;def has_api_key() -&gt; bool:&#10;    &quot;&quot;&quot;Return True if OPENAI_API_KEY was loaded from the environment.&quot;&quot;&quot;&#10;    return bool(API_KEY)&#10;&#10;&#10;def get_response(prompt: str, model: str = &quot;gpt-3.5-turbo&quot;, max_tokens: int = 500, temperature: float = 0.7) -&gt; str:&#10;    &quot;&quot;&quot;Send a prompt to OpenAI Chat Completions and return the assistant reply as text.&#10;&#10;    Raises RuntimeError if the API key is not configured.&#10;    &quot;&quot;&quot;&#10;    if not has_api_key():&#10;        raise RuntimeError(&quot;OPENAI_API_KEY is not set. Set it in environment or a .env file before calling get_response().&quot;)&#10;&#10;    if not prompt:&#10;        raise ValueError(&quot;prompt must be a non-empty string&quot;)&#10;&#10;    try:&#10;        response = openai.ChatCompletion.create(&#10;            model=model,&#10;            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],&#10;            max_tokens=max_tokens,&#10;            temperature=temperature,&#10;        )&#10;        # Extract assistant text&#10;        text = response.choices[0].message.get(&quot;content&quot;)&#10;        if text is None:&#10;            # Fallback for unexpected response shape&#10;            text = response.choices[0].text if hasattr(response.choices[0], 'text') else &quot;&quot;&#10;        return text.strip()&#10;    except Exception as e:&#10;        raise RuntimeError(f&quot;OpenAI request failed: {e}&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # CLI usage: python client.py [prompt words...]&#10;    if len(sys.argv) &gt; 1:&#10;        prompt = &quot; &quot;.join(sys.argv[1:])&#10;    else:&#10;        try:&#10;            prompt = input(&quot;Enter prompt: &quot;)&#10;        except KeyboardInterrupt:&#10;            print(&quot;\nCancelled&quot;)&#10;            sys.exit(0)&#10;&#10;    try:&#10;        reply = get_response(prompt)&#10;        print(&quot;\n--- Assistant reply ---\n&quot;)&#10;        print(reply)&#10;    except Exception as exc:&#10;        print(f&quot;Error: {exc}&quot;)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/main.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/main.py" />
              <option name="originalContent" value="&#10;import time&#10;import pyttsx3&#10;import webbrowser&#10;import speech_recognition as sr&#10;import requests&#10;import os&#10;from sites_Library import sites&#10;from playable_Library import playables&#10;&#10;recognizer = sr.Recognizer()&#10;engine = pyttsx3.init()&#10;newsapikey = os.environ.get(&quot;NEWS_API_KEY&quot;)&#10;GITHUB_TOKEN = os.environ.get(&quot;GITHUB_MODELS_TOKEN&quot;)&#10;API_URL = &quot;https://models.github.ai/inference/chat/completions&quot;&#10;recognition_enabled = True&#10;&#10;def ask_github_model(prompt: str, model: str = &quot;openai/gpt-4o&quot;):&#10;    headers = {&#10;        &quot;Authorization&quot;: f&quot;Bearer {GITHUB_TOKEN}&quot;,&#10;        &quot;Accept&quot;: &quot;application/vnd.github+json&quot;,&#10;        &quot;Content-Type&quot;: &quot;application/json&quot;,&#10;        &quot;X-GitHub-Api-Version&quot;: &quot;2022-11-28&quot;&#10;    }&#10;    body = {&#10;        &quot;model&quot;: model,&#10;        &quot;messages&quot;: [&#10;            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}&#10;        ]&#10;    }&#10;&#10;    resp = requests.post(API_URL, json=body, headers=headers)&#10;    resp.raise_for_status()&#10;    data = resp.json()    # data(dict) te id and choices(list of dict) thakbe&#10;    return data[&quot;choices&quot;][0][&quot;message&quot;][&quot;content&quot;]&#10;&#10;def speak(text):&#10;    global recognition_enabled&#10;    recognition_enabled = False&#10;    engine.setProperty('rate', 130)&#10;    engine.setProperty('volume', 1.0)&#10;    engine.say(text)&#10;    engine.runAndWait()&#10;&#10;    time.sleep(0.5)&#10;    recognition_enabled = True&#10;&#10;def processCommand(c):&#10;    if c.lower().startswith(&quot;open&quot;):&#10;        site_name = c.lower().split(&quot; &quot;)[1]&#10;        webbrowser.open(sites.get(site_name))&#10;    &#10;    elif &quot;news&quot; in c.lower():&#10;        speak(&quot;top news are&quot;)&#10;        time.sleep(1)&#10;        r = requests.get(f&quot;https://newsapi.org/v2/top-headlines?country=us&amp;apiKey={newsapikey}&quot;)&#10;&#10;        if r.status_code == 200:&#10;            data = r.json()&#10;            articles = data[&quot;articles&quot;]&#10;            for article in articles:&#10;                speak(article[&quot;title&quot;]) &#10;                time.sleep(1)&#10;    &#10;    elif &quot;play&quot; in c.lower():&#10;        play_item = c.lower().split(&quot; &quot;)[1]&#10;        webbrowser.open(playables.get(play_item))&#10;&#10;    else:&#10;       try:&#10;            answer = ask_github_model(c)&#10;            speak(answer)&#10;       except Exception as e:&#10;            print(&quot;Error calling GitHub Models API:&quot;, e)&#10;&#10;def main():&#10;    speak(&quot;initializing Nexus...&quot;)&#10;&#10;    while True:&#10;        if not recognition_enabled:&#10;            continue&#10;&#10;        r = sr.Recognizer()&#10;        print(&quot;recognizing...&quot;)&#10;        try:&#10;            with sr.Microphone() as source:&#10;                audio = r.listen(source, timeout=2, phrase_time_limit=3)&#10;            word = r.recognize_google(audio)&#10;            print(&quot;You said: &quot; + word)&#10;            print()&#10;            &#10;            if word.lower() == &quot;nexus&quot;:&#10;                speak(&quot;yes&quot;)&#10;                print(&quot;nexus activated&quot;)&#10;                with sr.Microphone() as source:&#10;                    print(&quot;Listening...&quot;)&#10;                    audio = r.listen(source)&#10;                    command = r.recognize_google(audio)&#10;&#10;                    if command.lower() in (&quot;exit&quot;, &quot;quit&quot;, &quot;deactivate&quot;):&#10;                        speak(&quot;deactivating nexus.&quot;)&#10;                        break&#10;                    processCommand(command)&#10;        except Exception as e:&#10;            print(&quot;Error; {0}&quot;.format(e))&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
              <option name="updatedContent" value="import time&#10;import pyttsx3&#10;import webbrowser&#10;import speech_recognition as sr&#10;import requests&#10;import os&#10;from sites_Library import sites&#10;from playable_Library import playables&#10;&#10;recognizer = sr.Recognizer()&#10;engine = pyttsx3.init()&#10;newsapikey = os.environ.get(&quot;NEWS_API_KEY&quot;)&#10;GITHUB_TOKEN = os.environ.get(&quot;GITHUB_MODELS_TOKEN&quot;)&#10;API_URL = &quot;https://models.github.ai/inference/chat/completions&quot;&#10;recognition_enabled = True&#10;&#10;# Try to import the optional OpenAI client (client.py). If present and configured,&#10;# prefer it for conversational queries. Import safely so main.py still runs without it.&#10;try:&#10;    from client import has_api_key as openai_has_key, get_response as openai_get_response&#10;    OPENAI_AVAILABLE = True&#10;except Exception:&#10;    OPENAI_AVAILABLE = False&#10;&#10;&#10;def ask_github_model(prompt: str, model: str = &quot;openai/gpt-4o&quot;):&#10;    headers = {&#10;        &quot;Authorization&quot;: f&quot;Bearer {GITHUB_TOKEN}&quot;,&#10;        &quot;Accept&quot;: &quot;application/vnd.github+json&quot;,&#10;        &quot;Content-Type&quot;: &quot;application/json&quot;,&#10;        &quot;X-GitHub-Api-Version&quot;: &quot;2022-11-28&quot;&#10;    }&#10;    body = {&#10;        &quot;model&quot;: model,&#10;        &quot;messages&quot;: [&#10;            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}&#10;        ]&#10;    }&#10;&#10;    resp = requests.post(API_URL, json=body, headers=headers)&#10;    resp.raise_for_status()&#10;    data = resp.json()    # data(dict) te id and choices(list of dict) thakbe&#10;    return data[&quot;choices&quot;][0][&quot;message&quot;][&quot;content&quot;]&#10;&#10;&#10;def speak(text):&#10;    global recognition_enabled&#10;    recognition_enabled = False&#10;    engine.setProperty('rate', 130)&#10;    engine.setProperty('volume', 1.0)&#10;    engine.say(text)&#10;    engine.runAndWait()&#10;&#10;    time.sleep(0.5)&#10;    recognition_enabled = True&#10;&#10;&#10;def processCommand(c):&#10;    if c.lower().startswith(&quot;open&quot;):&#10;        site_name = c.lower().split(&quot; &quot;)[1]&#10;        webbrowser.open(sites.get(site_name))&#10;    &#10;    elif &quot;news&quot; in c.lower():&#10;        speak(&quot;top news are&quot;)&#10;        time.sleep(1)&#10;        r = requests.get(f&quot;https://newsapi.org/v2/top-headlines?country=us&amp;apiKey={newsapikey}&quot;)&#10;&#10;        if r.status_code == 200:&#10;            data = r.json()&#10;            articles = data[&quot;articles&quot;]&#10;            for article in articles:&#10;                speak(article[&quot;title&quot;]) &#10;                time.sleep(1)&#10;    &#10;    elif &quot;play&quot; in c.lower():&#10;        play_item = c.lower().split(&quot; &quot;)[1]&#10;        webbrowser.open(playables.get(play_item))&#10;&#10;    else:&#10;       try:&#10;            # Prefer local OpenAI client when available and configured, otherwise use GitHub Models&#10;            if OPENAI_AVAILABLE and openai_has_key():&#10;                answer = openai_get_response(c)&#10;            else:&#10;                answer = ask_github_model(c)&#10;            speak(answer)&#10;       except Exception as e:&#10;            print(&quot;Error calling model API:&quot;, e)&#10;&#10;&#10;def main():&#10;    speak(&quot;initializing Nexus...&quot;)&#10;&#10;    while True:&#10;        if not recognition_enabled:&#10;            continue&#10;&#10;        r = sr.Recognizer()&#10;        print(&quot;recognizing...&quot;)&#10;        try:&#10;            with sr.Microphone() as source:&#10;                audio = r.listen(source, timeout=2, phrase_time_limit=3)&#10;            word = r.recognize_google(audio)&#10;            print(&quot;You said: &quot; + word)&#10;            print()&#10;            &#10;            if word.lower() == &quot;nexus&quot;:&#10;                speak(&quot;yes&quot;)&#10;                print(&quot;nexus activated&quot;)&#10;                with sr.Microphone() as source:&#10;                    print(&quot;Listening...&quot;)&#10;                    audio = r.listen(source)&#10;                    command = r.recognize_google(audio)&#10;&#10;                    if command.lower() in (&quot;exit&quot;, &quot;quit&quot;, &quot;deactivate&quot;):&#10;                        speak(&quot;deactivating nexus.&quot;)&#10;                        break&#10;                    processCommand(command)&#10;        except Exception as e:&#10;            print(&quot;Error; {0}&quot;.format(e))&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>